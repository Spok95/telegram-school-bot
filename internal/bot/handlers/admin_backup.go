package handlers

import (
	"archive/zip"
	"bytes"
	"database/sql"
	"encoding/csv"
	"fmt"
	"io/fs"
	"log"
	"os"
	"path/filepath"
	"strings"
	"time"

	"github.com/Spok95/telegram-school-bot/internal/bot/handlers/migrations"
	"github.com/Spok95/telegram-school-bot/internal/db"
	tgbotapi "github.com/go-telegram-bot-api/telegram-bot-api/v5"
)

// HandleAdminBackup ‚Äî —Å–æ–∑–¥–∞—ë—Ç ZIP —Å CSV-–¥–∞–º–ø–∞–º–∏ –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü + –º–∏–≥—Ä–∞—Ü–∏—è–º–∏
func HandleAdminBackup(bot *tgbotapi.BotAPI, database *sql.DB, chatID int64) {
	user, err := db.GetUserByTelegramID(database, chatID)
	if err != nil || user == nil || user.Role == nil || *user.Role != "admin" {
		bot.Send(tgbotapi.NewMessage(chatID, "üö´ –¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞"))
		return
	}
	bot.Send(tgbotapi.NewMessage(chatID, "‚åõ –î–µ–ª–∞—é –±—ç–∫–∞–ø –±–∞–∑—ã‚Ä¶"))

	path, size, err := dumpDatabaseToZip(database)
	if err != nil {
		log.Println("backup error:", err)
		bot.Send(tgbotapi.NewMessage(chatID, fmt.Sprintf("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–¥–µ–ª–∞—Ç—å –±—ç–∫–∞–ø: %v", err)))
		return
	}
	defer os.Remove(path)

	// ~50 –ú–ë –ª–∏–º–∏—Ç Telegram-–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –ë–µ—Ä—ë–º –∑–∞–ø–∞—Å.
	if size > 48*1024*1024 {
		bot.Send(tgbotapi.NewMessage(chatID,
			fmt.Sprintf("‚ö†Ô∏è –ë—ç–∫–∞–ø –ø–æ–ª—É—á–∏–ª—Å—è %d –ú–ë ‚Äî —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è Telegram. "+
				"–°–¥–µ–ª–∞–π—Ç–µ full dump: docker compose exec -T postgres pg_dump -U school -d school | gzip > backup.sql.gz", size/1024/1024)))
		return
	}

	f, _ := os.Open(path)
	defer f.Close()
	// –í —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏ go-telegram-bot-api —É FileReader –Ω–µ—Ç –ø–æ–ª—è Size
	doc := tgbotapi.NewDocument(chatID, tgbotapi.FileReader{
		Reader: f,
		Name:   filepath.Base(path),
	})
	doc.Caption = "üíæ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è –±–∞–∑—ã (CSV + –º–∏–≥—Ä–∞—Ü–∏–∏)"
	bot.Send(doc)
}

// dumpDatabaseToZip: –≤—ã–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü public-—Å—Ö–µ–º—ã –≤ CSV + –≤–ª–æ–∂–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–π –∏ metadata.json
func dumpDatabaseToZip(database *sql.DB) (string, int64, error) {
	rows, err := database.Query(`
		SELECT table_name
		FROM information_schema.tables
		WHERE table_schema='public' AND table_type='BASE TABLE'
		ORDER BY table_name`)
	if err != nil {
		return "", 0, err
	}
	defer rows.Close()

	var tables []string
	for rows.Next() {
		var t string
		if err := rows.Scan(&t); err != nil {
			return "", 0, err
		}
		tables = append(tables, t)
	}

	buf := &bytes.Buffer{}
	zw := zip.NewWriter(buf)

	// metadata.json
	meta := fmt.Sprintf(`{"created_at":"%s","version":"%s"}`,
		time.Now().Format(time.RFC3339), os.Getenv("GIT_SHA"))
	if w, err := zw.Create("metadata.json"); err == nil {
		_, _ = w.Write([]byte(meta))
	}

	// –º–∏–≥—Ä–∞—Ü–∏–∏ (–∏–∑ embed FS)
	_ = fsWalk(migrations.FS, ".", func(path string, data []byte) error {
		w, err := zw.Create(filepath.Join("migrations", path))
		if err != nil {
			return err
		}
		_, err = w.Write(data)
		return err
	})

	// CSV –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º
	for _, table := range tables {
		if strings.HasPrefix(table, "pg_") || table == "goose_db_version" {
			continue
		}
		if err := writeTableCSV(database, zw, table); err != nil {
			return "", 0, fmt.Errorf("table %s: %w", table, err)
		}
	}

	if err := zw.Close(); err != nil {
		return "", 0, err
	}

	filename := fmt.Sprintf("backup_%s.zip", time.Now().Format("20060102_150405"))
	path := filepath.Join(os.TempDir(), filename)
	if err := os.WriteFile(path, buf.Bytes(), 0644); err != nil {
		return "", 0, err
	}
	return path, int64(buf.Len()), nil
}

func writeTableCSV(database *sql.DB, zw *zip.Writer, table string) error {
	w, err := zw.Create(fmt.Sprintf("data/%s.csv", table))
	if err != nil {
		return err
	}
	query := fmt.Sprintf("SELECT * FROM"+" %s", quoteIdent(table))
	rows, err := database.Query(query)
	if err != nil {
		return err
	}
	defer rows.Close()

	cols, err := rows.Columns()
	if err != nil {
		return err
	}
	cw := csv.NewWriter(w)
	if err := cw.Write(cols); err != nil {
		return err
	}

	vals := make([]any, len(cols))
	ptrs := make([]any, len(cols))
	for i := range vals {
		ptrs[i] = &vals[i]
	}
	for rows.Next() {
		if err := rows.Scan(ptrs...); err != nil {
			return err
		}
		rec := make([]string, len(cols))
		for i, v := range vals {
			// NULL ‚Üí –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å –∏–º–ø–æ—Ä—Ç–æ–º)
			if v == nil {
				rec[i] = ""
				continue
			}
			// []byte ‚Üí —Ç–µ–∫—Å—Ç
			if b, ok := v.([]byte); ok {
				rec[i] = string(b)
				continue
			}
			// time.Time ‚Üí —Å—Ç–∞–±–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
			if t, ok := v.(time.Time); ok {
				rec[i] = t.Format(time.RFC3339Nano)
				continue
			}
			// –æ—Å—Ç–∞–ª—å–Ω–æ–µ –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞
			rec[i] = fmt.Sprint(v)
		}
		if err := cw.Write(rec); err != nil {
			return err
		}
	}
	cw.Flush()
	return cw.Error()
}

// quoteIdent ‚Äî —ç–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è SQL
func quoteIdent(id string) string {
	return `"` + strings.ReplaceAll(id, `"`, `""`) + `"`
}

// fsWalk –æ–±—Ö–æ–¥ embed.FS
func fsWalk(fsys fs.ReadFileFS, root string, fn func(path string, data []byte) error) error {
	rd, ok := fsys.(fs.ReadDirFS)
	if !ok {
		return nil
	}
	entries, err := rd.ReadDir(root)
	if err != nil {
		return err
	}
	for _, e := range entries {
		p := filepath.Join(root, e.Name())
		if e.IsDir() {
			if err := fsWalk(fsys, p, fn); err != nil {
				return err
			}
			continue
		}
		data, err := fsys.ReadFile(p)
		if err != nil {
			return err
		}
		if err := fn(strings.TrimPrefix(p, "./"), data); err != nil {
			return err
		}
	}
	return nil
}
